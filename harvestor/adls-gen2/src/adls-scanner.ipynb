{"cells":[{"cell_type":"code","source":["import os\nfrom azure.common.credentials import ServicePrincipalCredentials\nfrom azure.mgmt.resource import ResourceManagementClient\nfrom azure.mgmt.storage import StorageManagementClient\nfrom azure.storage.blob import BlockBlobService\nimport json\nimport time\nfrom datetime import datetime"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":1},{"cell_type":"markdown","source":["Get all the variables from cluster's environment variables. These variables can be pushed to cluster's environment variable either manually or via DevOps pipleline while provisioning the cluster"],"metadata":{}},{"cell_type":"code","source":["# Get Environment varaibles\nKeyVault_Scope = os.environ['KEYVAULT_SCOPE']\nKeyVault_ADLSGen2_Access_Secret_Name = os.environ['KEYVAULT_ADLSGEN2_ACCESS_SECRET_NAME']\nADLSGen2_URL = os.environ['ADLSGEN2_URL']\n#ADLSGen2_FileSystem = os.environ['ADLSGen2_FileSystem']\nKeyVault_BlobStorage_Access_Secret_Name = os.environ['KEYVAULT_BLOBSTORAGE_ACCESS_SECRET_NAME']\nBlobStorage_URL = os.environ['BLOBSTORAGE_URL']\nBlobStorage_Output_Container = os.environ['BLOBSTORAGE_OUTPUT_CONTAINER']\nScan_Depth=os.environ['SCAN_DEPTH']\nAAD_Client_Id=os.environ['AAD_CLIENT_ID']\nKeyVault_Client_Secret_Secret_Name=os.environ['KEYVAULT_CLIENT_SECRET_SECRET_NAME']\nADLSGen2_Resource_Group=os.environ['ADLSGEN2_RESOURCE_GROUP']\nADLSGen2_Subscription_Id=os.environ['ADLSGEN2_SUBSCRIPTION_ID']\nAAD_Tenant_Id=os.environ['AAD_TENANT_ID']"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"markdown","source":["Set spart configuration to access ADLS Gen2 file system. This python job using ADLS storage keys to access the file system from Spark."],"metadata":{}},{"cell_type":"code","source":["spark.conf.set(\n  \"fs.azure.account.key.\"+ADLSGen2_URL,\n  dbutils.secrets.get(scope = KeyVault_Scope, key =KeyVault_ADLSGen2_Access_Secret_Name ))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":5},{"cell_type":"markdown","source":["Set spark configuration to access Blob storage to store the output JSON file"],"metadata":{}},{"cell_type":"code","source":["spark.conf.set(\n  \"fs.azure.account.key.\"+BlobStorage_URL,\n dbutils.secrets.get(scope = KeyVault_Scope, key = KeyVault_BlobStorage_Access_Secret_Name))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":7},{"cell_type":"markdown","source":["Method to upload create file in Azure blob storage. <br>\nInputs : Content, file name"],"metadata":{}},{"cell_type":"code","source":["def upload_to_blob(content, file_name):\n  try:    \n    timenow = datetime.now()   \n    file_name = file_name+str(timenow.strftime(\"-%m%d%Y-%H-%M-%S\"))+\".json\"\n    result = dbutils.fs.put(\"wasbs://\"+BlobStorage_Output_Container+\"@\"+BlobStorage_URL+\"/\"+file_name,content,True)\n    if result == True:\n      print('Successfully created file: '+file_name)\n    else:\n      print(\"File creation failed\")\n  except Exception as e:\n    print('Error occurred while creating blob', e)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":9},{"cell_type":"markdown","source":["Method to make JSON in a needed format <br>\nInput -  list <br>\nOutput - Json String"],"metadata":{}},{"cell_type":"code","source":["def makeoutputjson_storageaccount(name,subscriptionId,resourceGroupName,location,createTime,SKU):\n  entity_json ={\n    \"entity_type_name\":\"azure_storage_account\",\n    \"created_by\":\"harvester\",\n     \"attributes\":[\n         {\n             \"attr_name\":\"qualifiedName\",\n             \"attr_value\":\"\",\n             \"is_entityref\": False\n         },\n         {\n            \"attr_name\":\"name\",\n            \"attr_value\":name,\n            \"is_entityref\": False\n        },\n        {\n            \"attr_name\":\"subscriptionId\",\n            \"attr_value\":subscriptionId,\n            \"is_entityref\": False\n        }, \n        {\n            \"attr_name\":\"resourceGroupName\",\n            \"attr_value\":resourceGroupName,\n            \"is_entityref\": False\n        },\n        {\n            \"attr_name\":\"location\",\n            \"attr_value\":location,\n            \"is_entityref\": False\n        },\n        {\n            \"attr_name\":\"createTime\",\n            \"attr_value\":int(float(createTime)),\n            \"is_entityref\": False\n        },\n        {\n            \"attr_name\":\"accessTier\",\n            \"attr_value\":\"Unknown\",\n            \"is_entityref\": False\n        },\n        {\n            \"attr_name\":\"SKU\",\n            \"attr_value\":SKU,\n            \"is_entityref\": False\n        },\n        {\n            \"attr_name\":\"kind\",\n            \"attr_value\":\"StorageV2\",\n            \"is_entityref\": False\n        }\n     ]\n  }\n  json_string= json.dumps(entity_json)\n  return json_string"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":11},{"cell_type":"code","source":["def makeoutputjson_filesystem(name):\n  entity_json ={\n      \"entity_type_name\": \"azure_datalake_gen2_filesystem\",\n      \"created_by\": \"harvester\",\n      \"attributes\": [{\n          \"attr_name\": \"qualifiedName\",\n          \"attr_value\": \"\",\n          \"is_entityref\": False\n       }, \n        {\n          \"attr_name\": \"name\",\n          \"attr_value\": name,\n          \"is_entityref\": False\n      }\n      ]\n    }\n  json_string= json.dumps(entity_json)\n  return json_string\n  "],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":12},{"cell_type":"code","source":["def makeoutputjson_service(name):\n  entity_json ={\n      \"entity_type_name\": \"azure_datalake_gen2_service\",\n      \"created_by\": \"harvester\",\n      \"attributes\": [{\n          \"attr_name\": \"qualifiedName\",\n          \"attr_value\": \"\",\n          \"is_entityref\": False\n       }, \n        {\n          \"attr_name\": \"name\",\n          \"attr_value\": name,\n          \"is_entityref\": False\n      }\n      ]\n    }\n  json_string= json.dumps(entity_json)\n  return json_string\n  "],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":13},{"cell_type":"code","source":["def make_output_json(entitylist):\n  entity_final=[]\n  for entity in entitylist:\n    if entity.endswith('/'):\n      entity=entity[0:len(entity)-1]      \n    entity_json ={\n      \"entity_type_name\": \"azure_datalake_gen2_resource_set\",\n      \"created_by\": \"harvester\",\n      \"attributes\": [{\n          \"attr_name\": \"qualifiedName\",\n          \"attr_value\": \"\",\n          \"is_entityref\": False\n       }, \n        {\n          \"attr_name\": \"name\",\n          \"attr_value\": entity,\n          \"is_entityref\": False\n      }\n      ]\n    }\n    entity_final.append(entity_json)\n  json_string= json.dumps(entity_final)\n  return json_string"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":14},{"cell_type":"markdown","source":["Method to scan the ADLS Gen 2 file system folders recursively using databricks dbutils"],"metadata":{}},{"cell_type":"code","source":["def getpath(path, level, entitylist, root_path ):  \n  files = dbutils.fs.ls(path)\n  for file in files:    \n    pathvalue = str(file.path)      \n    pathvalue_string = pathvalue.split(root_path)      \n    pathvalue_entity =pathvalue_string[-1]    \n    entitylist.append(pathvalue_entity)\n    if level <= int(Scan_Depth):\n        newlevel= level+1        \n        getpath(file.path,newlevel,entitylist,root_path)\n  return entitylist"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":16},{"cell_type":"code","source":[" \ndef scan_file_system(filesystem_name, account_url):  \n  entitylist=[]\n  startlevel =1\n  try:    \n    root_path = \"abfss://\"+filesystem_name+\"@\"+account_url+\"/\"\n    entitylist = getpath(root_path,startlevel,entitylist,root_path)\n  except:\n    print('Error in scan file system')\n  finally:\n    return entitylist"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":17},{"cell_type":"markdown","source":["<b>Main method</b> <br>\nThis script is using Azure service principal to get access to the storage account properties <br>\nService principal client id is stored in environment variable and secrets are pulled from Azure KeyVault <br>\nThis script doesn't mount ADLS Gen 2 file system to databricks, instead it directly access the file system"],"metadata":{}},{"cell_type":"code","source":["subscription_id =  ADLSGen2_Subscription_Id\nad_client_id=AAD_Client_Id\nad_client_secret=dbutils.secrets.get(scope = KeyVault_Scope, key =KeyVault_Client_Secret_Secret_Name ) \nad_tenantid=AAD_Tenant_Id\n#\nresource_group_name=ADLSGen2_Resource_Group\nstorage_account_name=ADLSGen2_URL[0:ADLSGen2_URL.find('.')]\n#Make credential object\ncredentials = ServicePrincipalCredentials(client_id=ad_client_id, secret=ad_client_secret, tenant=ad_tenantid)\nresource_client = ResourceManagementClient(credentials, subscription_id)\nstorage_client = StorageManagementClient(credentials, subscription_id)\nstorage_account = storage_client.storage_accounts.get_properties(resource_group_name, storage_account_name)\n# Get properties of storage account\nsa_creation_time=storage_account.creation_time.strftime(\"%Y-%m-%d %H:%M:%S\")\nsa_creation_time_test=str(storage_account.creation_time.timestamp())\nsa_kind=storage_account.kind\nsa_location=storage_account.location\nsa_name=storage_account.name\nsa_sku=storage_account.sku.name\n# Go further only for Storage Gen 2\nif sa_kind =='StorageV2':\n  # make output json for storage account\n  output_json_sa = makeoutputjson_storageaccount(sa_name,subscription_id,resource_group_name,sa_location,sa_creation_time_test,sa_sku)\n  output_json_service=makeoutputjson_service(sa_name)\n  #Get Storage Account file system properties\n  storage_keys = storage_client.storage_accounts.list_keys(resource_group_name, storage_account_name)\n  storage_keys = {v.key_name: v.value for v in storage_keys.keys}\n  block_blob_service = BlockBlobService(account_name=storage_account_name, account_key=storage_keys['key1'])\n  containers = block_blob_service.list_containers()\n  filesystems=[]\n  # Get file system names\n  for container in containers:\n      filesystems.append(container.name)\n  for filesystem in filesystems:  \n    # Pull the entity\n    # make output json for file system\n    output_json_fs= makeoutputjson_filesystem(filesystem)  \n    entitylist= scan_file_system(filesystem,ADLSGen2_URL)\n    if len(entitylist) >0:\n      output_json= make_output_json(entitylist)\n      output_json_filesystem={\n        \"azure_storage_account\":json.loads(output_json_sa),\n        \"azure_datalake_gen2_service\":json.loads(output_json_service),\n        \"azure_datalake_gen2_filesystem\":json.loads(output_json_fs),\n        \"azure_datalake_gen2_resource_set\":json.loads(output_json)\n      }\n      json_string_final= json.dumps(output_json_filesystem)\n      output_filename=filesystem+\"@\"+ADLSGen2_URL\n      upload_to_blob(json_string_final,output_filename)\nprint('Process completed')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Wrote 9868 bytes.\nSuccessfully created file: atlasparkhdi-container@beamdatav2.dfs.core.windows.net-11192019-08-43-42.json\nWrote 9870 bytes.\nSuccessfully created file: atlasparkhdireenu-2019-09-08t02-28-58-976z@beamdatav2.dfs.core.windows.net-11192019-08-43-49.json\nWrote 9880 bytes.\nSuccessfully created file: hdi-reenu-2019-09-08t02-47-44-383z@beamdatav2.dfs.core.windows.net-11192019-08-44-07.json\nWrote 413108 bytes.\nSuccessfully created file: sales@beamdatav2.dfs.core.windows.net-11192019-08-44-27.json\nWrote 784903 bytes.\nSuccessfully created file: salesdc@beamdatav2.dfs.core.windows.net-11192019-08-45-03.json\nWrote 392665 bytes.\nSuccessfully created file: salesdc02@beamdatav2.dfs.core.windows.net-11192019-08-45-23.json\nWrote 412100 bytes.\nSuccessfully created file: salesdc03@beamdatav2.dfs.core.windows.net-11192019-08-45-43.json\nWrote 1110542 bytes.\nSuccessfully created file: salesv2@beamdatav2.dfs.core.windows.net-11192019-08-51-44.json\nProcess completed\n</div>"]}}],"execution_count":19}],"metadata":{"name":"adls-harvester-v6","notebookId":4321354091179928},"nbformat":4,"nbformat_minor":0}
